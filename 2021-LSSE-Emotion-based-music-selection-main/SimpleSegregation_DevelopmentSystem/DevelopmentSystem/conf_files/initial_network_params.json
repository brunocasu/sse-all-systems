{"activation": ["relu", "logistic", "tanh"], "hidden_layer_sizes": [10, 200], "batch_size": [5, 20], "max_iter": [972], "random_state": [0]}